# Example .env file for ktalk-ai
# Copy to a file named `.env` and set appropriate values. Do NOT commit your real keys.

# OpenAI (optional). If set, app will use OpenAI by default.
# Leave empty if you only want to use a local Ollama backend.
OPENAI_API_KEY=

# Google Gemini API Key (optional)
GEMINI_API_KEY=

# Backend selection: 'openai', 'ollama', or 'gemini'.
# - To use your local Ollama `exaone` model, set MODEL_BACKEND=ollama
# - To use OpenAI's hosted API, set MODEL_BACKEND=openai
# - To use Google Gemini API, set MODEL_BACKEND=gemini
MODEL_BACKEND=ollama

# Ollama settings (only used when MODEL_BACKEND=ollama)
# Default assumes Ollama local server at port 11434 and model named `exaone`.
OLLAMA_URL=http://localhost:11434
# Recommended default: pick an exaone model available on your Ollama server.
# You can leave this blank to allow the app to auto-select a preferred exaone model at startup.
OLLAMA_MODEL=exaone3.5:7.8b
